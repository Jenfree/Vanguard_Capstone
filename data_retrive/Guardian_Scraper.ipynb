{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Guardian News API.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b1dpZrrITWM",
        "colab_type": "code",
        "outputId": "6146acac-5ebf-4d38-8891-95001e7f01e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "!pip install newspaper3k"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5)\n",
            "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.21.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13)\n",
            "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/90/18ac0e5340b6228c25cc8e79835c3811e7553b2b9ae87296dfeb62b7866d/tldextract-2.2.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 24.3MB/s \n",
            "\u001b[?25hCollecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.5.3)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 57.4MB/s \n",
            "\u001b[?25hCollecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.2.1->newspaper3k) (1.12.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (41.2.0)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Downloading https://files.pythonhosted.org/packages/23/9c/6e63c23c39e53d3df41c77a3d05a49a42c4e1383a6d2a5e3233161b89dbf/requests_file-1.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow>=3.3.0->newspaper3k) (0.46)\n",
            "Building wheels for collected packages: feedfinder2, jieba3k, feedparser, tinysegmenter\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp36-none-any.whl size=3356 sha256=aec57e62dc4a66b01e1d413986b01d5821047cad6c7fb8882afc0ddc1e296578\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp36-none-any.whl size=7398407 sha256=f941c26c014f03f118c643225efd947d3ea1596860f19cd188ea5785a0c2c927\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedparser: filename=feedparser-5.2.1-cp36-none-any.whl size=44940 sha256=de5d5a3f9686ad04b6a0456e65097cd1f72254b040e304e673ea2bb410249dbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp36-none-any.whl size=13538 sha256=1ff2d7db1b1920c8a3cedd42489235689078f17017f42630dd6fbb9766308acc\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "Successfully built feedfinder2 jieba3k feedparser tinysegmenter\n",
            "Installing collected packages: feedfinder2, requests-file, tldextract, jieba3k, cssselect, feedparser, tinysegmenter, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-5.2.1 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.4.3 tinysegmenter-0.3 tldextract-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cXFNO4f81bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf tempdata\n",
        "import requests\n",
        "import urllib.request\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from newspaper import Article\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w37F5qZUHMw",
        "colab_type": "code",
        "outputId": "47ac0c84-6ce2-4206-853e-4674031bf64d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2q5x9Ru6Cw5",
        "colab_type": "code",
        "outputId": "c1657b68-99a1-4357-9663-95989f955fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import json\n",
        "import requests\n",
        "from os import makedirs\n",
        "from os.path import join, exists\n",
        "from datetime import date, timedelta\n",
        "\n",
        "#ARTICLES_DIR = join('tempdata', 'articles')\n",
        "#makedirs(ARTICLES_DIR, exist_ok=True)\n",
        "# Sample URL\n",
        "#\n",
        "# http://content.guardianapis.com/search?from-date=2016-01-02&\n",
        "# to-date=2016-01-02&order-by=newest&show-fields=all&page-size=200\n",
        "# &api-key=your-api-key-goes-here\n",
        "\n",
        "#MY_API_KEY = open(\"creds_guardian.txt\").read().strip()\n",
        "API_ENDPOINT = 'http://content.guardianapis.com/search'\n",
        "my_params = {\n",
        "    'from-date': \"\",\n",
        "    'to-date': \"\",\n",
        "    'order-by': \"newest\",\n",
        "    'show-fields': 'all',\n",
        "    'page-size': 200,\n",
        "    'api-key': '8d8bb98e-effc-463a-8c9a-b58e1a517585'\n",
        "}\n",
        "\n",
        "\n",
        "# day iteration from here:\n",
        "# http://stackoverflow.com/questions/7274267/print-all-day-dates-between-two-dates\n",
        "start_date = date(2019, 5, 2)\n",
        "end_date = date(2019, 10, 5)\n",
        "dayrange = range((end_date - start_date).days + 1)\n",
        "#create a dataframe\n",
        "all_news = pd.DataFrame(columns=['timestamp', 'sectionName', 'url', 'content'])\n",
        "\n",
        "for daycount in dayrange:\n",
        "    dt = start_date + timedelta(days=daycount)\n",
        "    datestr = dt.strftime('%Y-%m-%d')\n",
        "    print(\"Downloading\", datestr)\n",
        "    all_results = []\n",
        "    my_params['from-date'] = datestr\n",
        "    my_params['to-date'] = datestr\n",
        "    current_page = 1\n",
        "    total_pages = 1\n",
        "    while current_page <= total_pages:\n",
        "        print(\"...page\", current_page)\n",
        "        my_params['page'] = current_page\n",
        "        resp = requests.get(API_ENDPOINT, my_params)\n",
        "        data = resp.json()\n",
        "        all_results.extend(data['response']['results'])\n",
        "        # if there is more than one page\n",
        "        current_page += 1\n",
        "        total_pages = data['response']['pages']\n",
        "        for item in all_results:\n",
        "          weburl = item['webUrl']\n",
        "          article = Article(weburl)\n",
        "          article.download()\n",
        "          try:\n",
        "            article.parse()\n",
        "          except:\n",
        "            print('Broken url: ', weburl)\n",
        "            pass\n",
        "          content = article.text\n",
        "\n",
        "          all_news = all_news.append({'timestamp': item['webPublicationDate'], \n",
        "                          'sectionName': item['sectionName'],\n",
        "                          'url': item['webUrl'],\n",
        "                          'content': content}, ignore_index=True)\n",
        "          #print(item['webUrl'])\n",
        "              \n",
        "all_news.to_csv('all_news2019_2.csv')\n",
        "!cp all_news2019_2.csv drive/My\\ Drive/\n",
        "print('Done!')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 2019-05-02\n",
            "...page 1\n",
            "Broken url:  https://www.theguardian.com/world/2019/may/02/venezuela-military-and-maduro-hold-early-morning-parade-we-will-never-surrender\n",
            "...page 2\n",
            "Downloading 2019-05-03\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-04\n",
            "...page 1\n",
            "Downloading 2019-05-05\n",
            "...page 1\n",
            "Broken url:  https://www.theguardian.com/world/2019/may/05/danish-far-right-party-stram-kurs-calling-for-muslim-deportation-to-stand-in-election\n",
            "...page 2\n",
            "Downloading 2019-05-06\n",
            "...page 1\n",
            "Downloading 2019-05-07\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-08\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-09\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-10\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-11\n",
            "...page 1\n",
            "Downloading 2019-05-12\n",
            "...page 1\n",
            "...page 2\n",
            "Broken url:  https://www.theguardian.com/artanddesign/2019/may/12/your-pictures-share-your-photos-on-the-theme-of-dramatic\n",
            "Downloading 2019-05-13\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-14\n",
            "...page 1\n",
            "Broken url:  https://www.theguardian.com/music/2019/may/14/letter-miles-wootton-obituary\n",
            "...page 2\n",
            "Downloading 2019-05-15\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-16\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-17\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-18\n",
            "...page 1\n",
            "Downloading 2019-05-19\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-20\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-21\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-22\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-23\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-24\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-25\n",
            "...page 1\n",
            "Downloading 2019-05-26\n",
            "...page 1\n",
            "Downloading 2019-05-27\n",
            "...page 1\n",
            "Downloading 2019-05-28\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-29\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-30\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-05-31\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-01\n",
            "...page 1\n",
            "Downloading 2019-06-02\n",
            "...page 1\n",
            "Downloading 2019-06-03\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-04\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-05\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-06\n",
            "...page 1\n",
            "Broken url:  https://www.theguardian.com/sport/2019/jun/06/australia-west-indies-cricket-world-cup-match-report\n",
            "...page 2\n",
            "Downloading 2019-06-07\n",
            "...page 1\n",
            "...page 2\n",
            "...page 3\n",
            "Downloading 2019-06-08\n",
            "...page 1\n",
            "Downloading 2019-06-09\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-10\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-11\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-12\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-13\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-14\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-15\n",
            "...page 1\n",
            "Downloading 2019-06-16\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-17\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-18\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-19\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-20\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-21\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-22\n",
            "...page 1\n",
            "Downloading 2019-06-23\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-24\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-25\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-26\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-27\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-28\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-06-29\n",
            "...page 1\n",
            "Downloading 2019-06-30\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-01\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-02\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-03\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-04\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-05\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-06\n",
            "...page 1\n",
            "Downloading 2019-07-07\n",
            "...page 1\n",
            "Downloading 2019-07-08\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-09\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-10\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-11\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-12\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-13\n",
            "...page 1\n",
            "Downloading 2019-07-14\n",
            "...page 1\n",
            "Downloading 2019-07-15\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-16\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-17\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-18\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-19\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-20\n",
            "...page 1\n",
            "Downloading 2019-07-21\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-22\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-23\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-24\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-25\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-26\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-27\n",
            "...page 1\n",
            "Downloading 2019-07-28\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-29\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-30\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-07-31\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-01\n",
            "...page 1\n",
            "Downloading 2019-08-02\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-03\n",
            "...page 1\n",
            "Downloading 2019-08-04\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-05\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-06\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-07\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-08\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-09\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-10\n",
            "...page 1\n",
            "Downloading 2019-08-11\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-12\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-13\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-14\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-15\n",
            "...page 1\n",
            "Downloading 2019-08-16\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-17\n",
            "...page 1\n",
            "Downloading 2019-08-18\n",
            "...page 1\n",
            "Downloading 2019-08-19\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-20\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-21\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-22\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-23\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-24\n",
            "...page 1\n",
            "Downloading 2019-08-25\n",
            "...page 1\n",
            "Downloading 2019-08-26\n",
            "...page 1\n",
            "Downloading 2019-08-27\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-28\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-29\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-30\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-08-31\n",
            "...page 1\n",
            "Downloading 2019-09-01\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-02\n",
            "...page 1\n",
            "Downloading 2019-09-03\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-04\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-05\n",
            "...page 1\n",
            "Downloading 2019-09-06\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-07\n",
            "...page 1\n",
            "Downloading 2019-09-08\n",
            "...page 1\n",
            "Downloading 2019-09-09\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-10\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-11\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-12\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-13\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-14\n",
            "...page 1\n",
            "Downloading 2019-09-15\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-16\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-17\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-18\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-19\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-20\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-21\n",
            "...page 1\n",
            "Downloading 2019-09-22\n",
            "...page 1\n",
            "Broken url:  https://www.theguardian.com/crosswords/cryptic/27933\n",
            "Downloading 2019-09-23\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-24\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-25\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-26\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-27\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-09-28\n",
            "...page 1\n",
            "Downloading 2019-09-29\n",
            "...page 1\n",
            "Downloading 2019-09-30\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-10-01\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-10-02\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-10-03\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-10-04\n",
            "...page 1\n",
            "...page 2\n",
            "Downloading 2019-10-05\n",
            "...page 1\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zIkW3TH6JuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}