{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime\n",
    "import spacy\n",
    "import re\n",
    "import subprocess\n",
    "import multiprocessing, datetime\n",
    "import yfinance as yf\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/news_guardian_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269823"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of companies\n",
    "library = {'Apple', 'Apple Inc.', 'Ford', 'Airbus', 'Boeing', 'Google', 'Google Inc.', 'Huawei', 'Tesco', 'Amazon', 'Tesla', 'Patisserie Holdings', 'the Bank of England', 'Honda', 'Nissan', \n",
    "           'British Gas', 'Toyota', 'BMW', 'Scunthorpe', 'Scottish Power', \"Sainsbury's Energy\", 'Toto', 'Greybull Capital',\n",
    "           'the European Central Bank', 'Morgan Stanley', 'HSBC', 'Nissan', 'Goldman Sachs', 'British Steel', 'Microsoft', 'LinkedIn',\n",
    "           'Facebook', 'Lenovo', 'Netflix', 'eBay', 'Paypal', 'Samsung', 'Alphabet', 'Intel', 'IBM', 'Oracle', 'Alibaba', 'Tencent', 'Cisco', 'SAP',\n",
    "           'NVIDIA', 'Adobe', 'Texas Instruments', 'Broadcom', 'Accenture', 'Salesforce', 'Qualcomm', 'Sony', 'Applied Materials', 'Shell', 'Chevron Corporation',\n",
    "           'BP', 'PetroChina', 'Sinopec', 'Schlumberger', 'Enterprise Products', 'ConocoPhillips', 'EOG Resources', 'Suncor Energy', 'Occidental Petroleum Corporation',\n",
    "           'Kinder Morgan', 'Phillips 66', 'Halliburton', 'BNP Paribas', 'JP Morgan', 'Bank of America', 'Wells Fargo', 'Citigroup', 'American Express',\n",
    "           'Volkswagen', 'General Motors', 'GM', 'Pegatron', 'Fujitsu', 'Mitsubishi', 'Honeywell', 'Caterpillar', 'Hewlett-Packard', 'United Technologies',\n",
    "           'Dell', 'Hitachi', 'General Electric', 'HP', 'PNC', 'Capital One', 'State Farm', 'UBS', 'Siemens', 'Vestas', 'NextEra Energy', 'Oneok',\n",
    "           'Reliance Steel', 'Tenneco', 'Chesapeake Energy', 'Steel Dynamics', 'Williams Cos.', 'Williams Partners', 'Federal-Mogul'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "texts = df['content'].tolist()\n",
    "texts = [str(x) for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_extraction(text):\n",
    "    orgs = \"\"\n",
    "    doc = nlp(text)\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_ != 'ORG' or entity.text not in library:\n",
    "            continue\n",
    "        org = re.sub('\\n|Äôs|(|)|–', '', entity.text)\n",
    "        if org == 'Apple Inc.':\n",
    "            org = 'Apple'\n",
    "        if org == 'Google Inc.':\n",
    "            org = 'Google'\n",
    "        orgs = orgs + org + \"|\"\n",
    "    if orgs == \"\":\n",
    "        return \"NOENTITY\"\n",
    "    return orgs.rstrip(\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-11 21:55:51.296495\n",
      "2019-11-12 00:53:20.554817\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "with multiprocessing.Pool(int(multiprocessing.cpu_count()-5)) as pool:\n",
    "    new_entities = pool.map(entity_extraction, [x for x in texts])\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269823"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['entity'] = new_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/news_guardian_entity.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[ df['entity'] == '' ].index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29325"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2017-10-01T18:55:00Z</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>https://www.theguardian.com/commentisfree/2017...</td>\n",
       "      <td>Ikea celebrates its 30th birthday in the UK th...</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>eBay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2017-10-01T18:05:36Z</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://www.theguardian.com/business/2017/oct/...</td>\n",
       "      <td>Alan Quinn criticises Tory governments for the...</td>\n",
       "      <td>3.673728e-07</td>\n",
       "      <td>Boeing|Boeing|Boeing|Boeing|Boeing|Boeing|Airb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2017-10-01T17:40:37Z</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://www.theguardian.com/business/2017/oct/...</td>\n",
       "      <td>The country’s largest supplier of supermarket ...</td>\n",
       "      <td>2.035094e-02</td>\n",
       "      <td>Tesco|Tesco|Tesco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2017-10-01T13:36:30Z</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://www.theguardian.com/business/2017/oct/...</td>\n",
       "      <td>Tesco’s recovery under Dave Lewis since a seri...</td>\n",
       "      <td>9.995096e-01</td>\n",
       "      <td>Tesco|Tesco|Dell|the Bank of England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2017-10-01T13:00:03Z</td>\n",
       "      <td>Global</td>\n",
       "      <td>https://www.theguardian.com/us-news/2017/oct/0...</td>\n",
       "      <td>On an evening last September, I received a cal...</td>\n",
       "      <td>1.971618e-03</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp sectionName  \\\n",
       "33   2017-10-01T18:55:00Z     Opinion   \n",
       "40   2017-10-01T18:05:36Z    Business   \n",
       "48   2017-10-01T17:40:37Z    Business   \n",
       "95   2017-10-01T13:36:30Z    Business   \n",
       "101  2017-10-01T13:00:03Z      Global   \n",
       "\n",
       "                                                   url  \\\n",
       "33   https://www.theguardian.com/commentisfree/2017...   \n",
       "40   https://www.theguardian.com/business/2017/oct/...   \n",
       "48   https://www.theguardian.com/business/2017/oct/...   \n",
       "95   https://www.theguardian.com/business/2017/oct/...   \n",
       "101  https://www.theguardian.com/us-news/2017/oct/0...   \n",
       "\n",
       "                                               content     sentiment  \\\n",
       "33   Ikea celebrates its 30th birthday in the UK th...  9.999999e-01   \n",
       "40   Alan Quinn criticises Tory governments for the...  3.673728e-07   \n",
       "48   The country’s largest supplier of supermarket ...  2.035094e-02   \n",
       "95   Tesco’s recovery under Dave Lewis since a seri...  9.995096e-01   \n",
       "101  On an evening last September, I received a cal...  1.971618e-03   \n",
       "\n",
       "                                                entity  \n",
       "33                                                eBay  \n",
       "40   Boeing|Boeing|Boeing|Boeing|Boeing|Boeing|Airb...  \n",
       "48                                   Tesco|Tesco|Tesco  \n",
       "95                Tesco|Tesco|Dell|the Bank of England  \n",
       "101                                           Facebook  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/news_guardian_entity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 269823 entries, 0 to 269822\n",
      "Data columns (total 6 columns):\n",
      "timestamp      269823 non-null object\n",
      "sectionName    269823 non-null object\n",
      "url            269823 non-null object\n",
      "content        269793 non-null object\n",
      "sentiment      269823 non-null float64\n",
      "entity         29325 non-null object\n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 12.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[ pd.isnull(df['entity'])].index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29325"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mat = np.asarray(df['sentiment'].tolist())\n",
    "Y_mat = Y_mat * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_dict = {}\n",
    "ctr = 0\n",
    "for entity_str in df['entity'].tolist():\n",
    "    entities = entity_str.split('|')\n",
    "    for _ in entities:\n",
    "        if not _ in entity_dict:\n",
    "            entity_dict[_] = ctr\n",
    "            ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eBay': 0,\n",
       " 'Boeing': 1,\n",
       " 'Airbus': 2,\n",
       " 'Tesco': 3,\n",
       " 'Dell': 4,\n",
       " 'the Bank of England': 5,\n",
       " 'Facebook': 6,\n",
       " 'the European Central Bank': 7,\n",
       " 'Netflix': 8,\n",
       " 'Google': 9,\n",
       " 'Amazon': 10,\n",
       " 'Tesla': 11,\n",
       " 'Ford': 12,\n",
       " 'British Steel': 13,\n",
       " 'Nissan': 14,\n",
       " 'Toyota': 15,\n",
       " 'Honda': 16,\n",
       " 'BMW': 17,\n",
       " 'General Motors': 18,\n",
       " 'Shell': 19,\n",
       " 'Greybull Capital': 20,\n",
       " 'HSBC': 21,\n",
       " 'Apple': 22,\n",
       " 'Intel': 23,\n",
       " 'Microsoft': 24,\n",
       " 'Scunthorpe': 25,\n",
       " 'Goldman Sachs': 26,\n",
       " 'Morgan Stanley': 27,\n",
       " 'PetroChina': 28,\n",
       " 'Samsung': 29,\n",
       " 'Sony': 30,\n",
       " 'HP': 31,\n",
       " 'Siemens': 32,\n",
       " 'IBM': 33,\n",
       " 'Volkswagen': 34,\n",
       " 'Adobe': 35,\n",
       " 'British Gas': 36,\n",
       " 'UBS': 37,\n",
       " 'Caterpillar': 38,\n",
       " 'Wells Fargo': 39,\n",
       " 'American Express': 40,\n",
       " 'Bank of America': 41,\n",
       " 'Hewlett-Packard': 42,\n",
       " 'GM': 43,\n",
       " 'Citigroup': 44,\n",
       " 'Hitachi': 45,\n",
       " 'Scottish Power': 46,\n",
       " 'BP': 47,\n",
       " 'JP Morgan': 48,\n",
       " 'BNP Paribas': 49,\n",
       " 'Huawei': 50,\n",
       " 'Oracle': 51,\n",
       " 'LinkedIn': 52,\n",
       " 'Mitsubishi': 53,\n",
       " 'Lenovo': 54,\n",
       " 'General Electric': 55,\n",
       " 'Accenture': 56,\n",
       " 'Cisco': 57,\n",
       " 'Sinopec': 58,\n",
       " 'Fujitsu': 59,\n",
       " 'SAP': 60,\n",
       " 'Tencent': 61,\n",
       " 'PNC': 62,\n",
       " 'ConocoPhillips': 63,\n",
       " 'Salesforce': 64,\n",
       " 'Broadcom': 65,\n",
       " 'Honeywell': 66,\n",
       " 'Alphabet': 67,\n",
       " 'Capital One': 68,\n",
       " 'State Farm': 69,\n",
       " 'Pegatron': 70,\n",
       " 'Chevron Corporation': 71,\n",
       " 'Patisserie Holdings': 72,\n",
       " 'Phillips 66': 73,\n",
       " 'Halliburton': 74,\n",
       " 'United Technologies': 75,\n",
       " 'Texas Instruments': 76}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame({\"company_name\": list(entity_dict.keys())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.to_csv(\"./data/company_table.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mat = np.zeros((len(df), len(entity_dict)))\n",
    "for row_ctr, entity_str in enumerate(df['entity'].tolist()):\n",
    "    entities = entity_str.split('|')\n",
    "    for _ in entities:\n",
    "        X_mat[row_ctr, entity_dict[_]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mat_sums = X_mat.sum(axis=1)\n",
    "X_mat = X_mat / X_mat_sums[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mat_sums = X_mat.sum(axis=1)\n",
    "X_mat = X_mat / X_mat_sums[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "#dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_mat.shape[0]\n",
    "m = X_mat.shape[1]\n",
    "X = torch.Tensor(X_mat).type(dtype)\n",
    "Y = torch.Tensor(Y_mat).type(dtype)\n",
    "W = torch.randn((m,n),requires_grad=True).type(dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(X,Y,W,lam1 = 1, lam2 = 1):\n",
    "    loss = lam1 * torch.norm(W, 1)\n",
    "    for _ in range(W.shape[1]-1):\n",
    "        loss += lam2 *  torch.norm(W[:,_]-W[:,_+1], 2)\n",
    "    loss += torch.norm(Y-torch.diag(torch.mm(X, W)), 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(2162990., grad_fn=<AddBackward0>) 2019-11-13 17:47:06.194888\n",
      "2 tensor(1926867.7500, grad_fn=<AddBackward0>) 2019-11-13 17:48:12.717438\n",
      "3 tensor(1765631.1250, grad_fn=<AddBackward0>) 2019-11-13 17:48:50.664755\n",
      "4 tensor(1642235.8750, grad_fn=<AddBackward0>) 2019-11-13 17:49:25.079782\n",
      "5 tensor(1538932.6250, grad_fn=<AddBackward0>) 2019-11-13 17:50:03.387416\n",
      "6 tensor(1451092.1250, grad_fn=<AddBackward0>) 2019-11-13 17:50:38.612669\n",
      "7 tensor(1373219.6250, grad_fn=<AddBackward0>) 2019-11-13 17:51:14.800812\n",
      "8 tensor(1304130.1250, grad_fn=<AddBackward0>) 2019-11-13 17:51:54.130369\n",
      "9 tensor(1241353.8750, grad_fn=<AddBackward0>) 2019-11-13 17:52:29.356249\n",
      "10 tensor(1184345.3750, grad_fn=<AddBackward0>) 2019-11-13 17:53:07.800842\n",
      "11 tensor(1131724.1250, grad_fn=<AddBackward0>) 2019-11-13 17:53:43.988231\n",
      "12 tensor(1083287.6250, grad_fn=<AddBackward0>) 2019-11-13 17:54:19.823244\n",
      "13 tensor(1038063.5625, grad_fn=<AddBackward0>) 2019-11-13 17:54:59.845233\n",
      "14 tensor(996083.8750, grad_fn=<AddBackward0>) 2019-11-13 17:55:36.672964\n",
      "15 tensor(956574.5625, grad_fn=<AddBackward0>) 2019-11-13 17:56:14.661020\n",
      "16 tensor(919638.3750, grad_fn=<AddBackward0>) 2019-11-13 17:56:49.882664\n",
      "17 tensor(884686.3125, grad_fn=<AddBackward0>) 2019-11-13 17:57:23.833673\n",
      "18 tensor(851846., grad_fn=<AddBackward0>) 2019-11-13 17:58:00.583585\n",
      "19 tensor(820601.7500, grad_fn=<AddBackward0>) 2019-11-13 17:58:37.530495\n",
      "20 tensor(791133.0625, grad_fn=<AddBackward0>) 2019-11-13 17:59:07.892770\n",
      "21 tensor(763029.9375, grad_fn=<AddBackward0>) 2019-11-13 17:59:46.685425\n",
      "22 tensor(736389.0625, grad_fn=<AddBackward0>) 2019-11-13 18:00:20.550995\n",
      "23 tensor(710894.6875, grad_fn=<AddBackward0>) 2019-11-13 18:00:54.072610\n",
      "24 tensor(686709.6250, grad_fn=<AddBackward0>) 2019-11-13 18:01:29.393908\n",
      "25 tensor(663480.6875, grad_fn=<AddBackward0>) 2019-11-13 18:02:06.246743\n",
      "26 tensor(641417.6250, grad_fn=<AddBackward0>) 2019-11-13 18:02:41.937033\n",
      "27 tensor(620133.4375, grad_fn=<AddBackward0>) 2019-11-13 18:03:16.996703\n",
      "28 tensor(599895.5000, grad_fn=<AddBackward0>) 2019-11-13 18:03:55.116134\n",
      "29 tensor(580348., grad_fn=<AddBackward0>) 2019-11-13 18:04:32.291387\n",
      "30 tensor(561757.9375, grad_fn=<AddBackward0>) 2019-11-13 18:05:06.922390\n",
      "31 tensor(543750.1250, grad_fn=<AddBackward0>) 2019-11-13 18:05:41.972959\n",
      "32 tensor(526603.3750, grad_fn=<AddBackward0>) 2019-11-13 18:06:19.716338\n",
      "33 tensor(509967.2812, grad_fn=<AddBackward0>) 2019-11-13 18:06:54.739847\n",
      "34 tensor(494094.0938, grad_fn=<AddBackward0>) 2019-11-13 18:07:32.090062\n",
      "35 tensor(478714.5000, grad_fn=<AddBackward0>) 2019-11-13 18:08:07.501976\n",
      "36 tensor(463989.5312, grad_fn=<AddBackward0>) 2019-11-13 18:08:42.741571\n",
      "37 tensor(449704.8125, grad_fn=<AddBackward0>) 2019-11-13 18:09:18.783436\n",
      "38 tensor(436024.8750, grad_fn=<AddBackward0>) 2019-11-13 18:09:55.225307\n",
      "39 tensor(422759.4062, grad_fn=<AddBackward0>) 2019-11-13 18:10:33.196054\n",
      "40 tensor(410032.6875, grad_fn=<AddBackward0>) 2019-11-13 18:11:07.313956\n",
      "41 tensor(397672.8125, grad_fn=<AddBackward0>) 2019-11-13 18:11:44.716564\n",
      "42 tensor(385801.2812, grad_fn=<AddBackward0>) 2019-11-13 18:12:18.233564\n",
      "43 tensor(374272.6562, grad_fn=<AddBackward0>) 2019-11-13 18:12:54.368939\n",
      "44 tensor(363209.3750, grad_fn=<AddBackward0>) 2019-11-13 18:13:32.450723\n",
      "45 tensor(352431.9688, grad_fn=<AddBackward0>) 2019-11-13 18:14:08.542566\n",
      "46 tensor(342097.0938, grad_fn=<AddBackward0>) 2019-11-13 18:14:45.798340\n",
      "47 tensor(332010., grad_fn=<AddBackward0>) 2019-11-13 18:15:20.738988\n",
      "48 tensor(322348.2188, grad_fn=<AddBackward0>) 2019-11-13 18:15:54.674841\n",
      "49 tensor(312898.3438, grad_fn=<AddBackward0>) 2019-11-13 18:16:31.825565\n",
      "50 tensor(303857.8125, grad_fn=<AddBackward0>) 2019-11-13 18:17:07.563967\n",
      "51 tensor(295010.5312, grad_fn=<AddBackward0>) 2019-11-13 18:17:46.527187\n",
      "52 tensor(286528.7188, grad_fn=<AddBackward0>) 2019-11-13 18:18:24.437949\n",
      "53 tensor(278235.5625, grad_fn=<AddBackward0>) 2019-11-13 18:19:02.150741\n",
      "54 tensor(270264.8438, grad_fn=<AddBackward0>) 2019-11-13 18:19:40.354048\n",
      "55 tensor(262477.7188, grad_fn=<AddBackward0>) 2019-11-13 18:20:17.732079\n",
      "56 tensor(254999.2812, grad_fn=<AddBackward0>) 2019-11-13 18:20:52.172985\n",
      "57 tensor(247680.3906, grad_fn=<AddBackward0>) 2019-11-13 18:21:27.722432\n",
      "58 tensor(240643.2969, grad_fn=<AddBackward0>) 2019-11-13 18:22:04.550197\n",
      "59 tensor(233763.2500, grad_fn=<AddBackward0>) 2019-11-13 18:22:40.365750\n",
      "60 tensor(227145.6250, grad_fn=<AddBackward0>) 2019-11-13 18:23:18.141567\n",
      "61 tensor(220664.6406, grad_fn=<AddBackward0>) 2019-11-13 18:23:53.747690\n",
      "62 tensor(214446.3125, grad_fn=<AddBackward0>) 2019-11-13 18:24:26.893108\n",
      "63 tensor(208336.8750, grad_fn=<AddBackward0>) 2019-11-13 18:25:02.669013\n",
      "64 tensor(202485.8594, grad_fn=<AddBackward0>) 2019-11-13 18:25:38.077090\n",
      "65 tensor(196724.8281, grad_fn=<AddBackward0>) 2019-11-13 18:26:18.625549\n",
      "66 tensor(191205.8438, grad_fn=<AddBackward0>) 2019-11-13 18:26:54.927982\n",
      "67 tensor(185781.9219, grad_fn=<AddBackward0>) 2019-11-13 18:27:34.740659\n",
      "68 tensor(180576.6250, grad_fn=<AddBackward0>) 2019-11-13 18:28:14.510170\n",
      "69 tensor(175464.0156, grad_fn=<AddBackward0>) 2019-11-13 18:28:49.867903\n",
      "70 tensor(170554.6719, grad_fn=<AddBackward0>) 2019-11-13 18:29:24.989995\n",
      "71 tensor(165731.5625, grad_fn=<AddBackward0>) 2019-11-13 18:30:03.941640\n",
      "72 tensor(161099.0156, grad_fn=<AddBackward0>) 2019-11-13 18:30:41.637706\n",
      "73 tensor(156546.8750, grad_fn=<AddBackward0>) 2019-11-13 18:31:18.856624\n",
      "74 tensor(152176.3438, grad_fn=<AddBackward0>) 2019-11-13 18:31:56.779469\n",
      "75 tensor(147874.9219, grad_fn=<AddBackward0>) 2019-11-13 18:32:34.297626\n",
      "76 tensor(143748.8906, grad_fn=<AddBackward0>) 2019-11-13 18:33:09.343560\n",
      "77 tensor(139685.7031, grad_fn=<AddBackward0>) 2019-11-13 18:33:45.967160\n",
      "78 tensor(135793.7031, grad_fn=<AddBackward0>) 2019-11-13 18:34:20.643847\n",
      "79 tensor(131955.7031, grad_fn=<AddBackward0>) 2019-11-13 18:34:54.086806\n",
      "80 tensor(128282.4609, grad_fn=<AddBackward0>) 2019-11-13 18:35:28.804934\n",
      "81 tensor(124659.4609, grad_fn=<AddBackward0>) 2019-11-13 18:36:09.249792\n",
      "82 tensor(121190.6406, grad_fn=<AddBackward0>) 2019-11-13 18:36:47.779867\n",
      "83 tensor(117761.1875, grad_fn=<AddBackward0>) 2019-11-13 18:37:26.852585\n",
      "84 tensor(114488.8984, grad_fn=<AddBackward0>) 2019-11-13 18:38:00.884795\n",
      "85 tensor(111252.0859, grad_fn=<AddBackward0>) 2019-11-13 18:38:37.965208\n",
      "86 tensor(108154.1484, grad_fn=<AddBackward0>) 2019-11-13 18:39:13.364502\n",
      "87 tensor(105098.3516, grad_fn=<AddBackward0>) 2019-11-13 18:39:51.927212\n",
      "88 tensor(102171.2266, grad_fn=<AddBackward0>) 2019-11-13 18:40:27.525169\n",
      "89 tensor(99281.8750, grad_fn=<AddBackward0>) 2019-11-13 18:41:03.444599\n",
      "90 tensor(96520.1172, grad_fn=<AddBackward0>) 2019-11-13 18:41:38.448427\n",
      "91 tensor(93787.0156, grad_fn=<AddBackward0>) 2019-11-13 18:42:13.436608\n",
      "92 tensor(91176.9141, grad_fn=<AddBackward0>) 2019-11-13 18:42:48.674103\n",
      "93 tensor(88600.6641, grad_fn=<AddBackward0>) 2019-11-13 18:43:25.322297\n",
      "94 tensor(86134.8906, grad_fn=<AddBackward0>) 2019-11-13 18:44:02.137884\n",
      "95 tensor(83698.3672, grad_fn=<AddBackward0>) 2019-11-13 18:44:39.615976\n",
      "96 tensor(81373.3672, grad_fn=<AddBackward0>) 2019-11-13 18:45:17.345710\n",
      "97 tensor(79076.8281, grad_fn=<AddBackward0>) 2019-11-13 18:45:53.666553\n",
      "98 tensor(76884.3438, grad_fn=<AddBackward0>) 2019-11-13 18:46:26.682477\n",
      "99 tensor(74718.9922, grad_fn=<AddBackward0>) 2019-11-13 18:47:04.940093\n",
      "100 tensor([ 1.0000, -1.0000, -0.9593,  ...,  1.0000, -1.0000,  1.0000])\n",
      "100 tensor(72655.6328, grad_fn=<AddBackward0>) 2019-11-13 18:47:38.266201\n",
      "101 tensor(70609.1797, grad_fn=<AddBackward0>) 2019-11-13 18:48:10.860980\n",
      "102 tensor(68671.8672, grad_fn=<AddBackward0>) 2019-11-13 18:48:45.136711\n",
      "103 tensor(66743.4609, grad_fn=<AddBackward0>) 2019-11-13 18:49:25.216361\n",
      "104 tensor(64914.1055, grad_fn=<AddBackward0>) 2019-11-13 18:49:58.410670\n",
      "105 tensor(63107.8398, grad_fn=<AddBackward0>) 2019-11-13 18:50:37.458325\n",
      "106 tensor(61380.1289, grad_fn=<AddBackward0>) 2019-11-13 18:51:12.452499\n",
      "107 tensor(59682.1172, grad_fn=<AddBackward0>) 2019-11-13 18:51:43.984409\n",
      "108 tensor(58061.1523, grad_fn=<AddBackward0>) 2019-11-13 18:52:19.111747\n",
      "109 tensor(56463.7734, grad_fn=<AddBackward0>) 2019-11-13 18:52:58.152671\n",
      "110 tensor(54941.2852, grad_fn=<AddBackward0>) 2019-11-13 18:53:30.358760\n",
      "111 tensor(53442.5977, grad_fn=<AddBackward0>) 2019-11-13 18:54:04.693193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 tensor(52016.1328, grad_fn=<AddBackward0>) 2019-11-13 18:54:41.429725\n",
      "113 tensor(50612.2578, grad_fn=<AddBackward0>) 2019-11-13 18:55:19.872131\n",
      "114 tensor(49274.7500, grad_fn=<AddBackward0>) 2019-11-13 18:55:55.052068\n",
      "115 tensor(47961.8359, grad_fn=<AddBackward0>) 2019-11-13 18:56:26.802322\n",
      "116 tensor(46713.0898, grad_fn=<AddBackward0>) 2019-11-13 18:56:59.487640\n",
      "117 tensor(45486.1211, grad_fn=<AddBackward0>) 2019-11-13 18:57:37.593619\n",
      "118 tensor(44317.0625, grad_fn=<AddBackward0>) 2019-11-13 18:58:14.970728\n",
      "119 tensor(43172.0117, grad_fn=<AddBackward0>) 2019-11-13 18:58:54.738901\n",
      "120 tensor(42083.3477, grad_fn=<AddBackward0>) 2019-11-13 18:59:30.833935\n",
      "121 tensor(41016.2617, grad_fn=<AddBackward0>) 2019-11-13 19:00:07.386235\n",
      "122 tensor(39999.6836, grad_fn=<AddBackward0>) 2019-11-13 19:00:41.778613\n",
      "123 tensor(39007.7578, grad_fn=<AddBackward0>) 2019-11-13 19:01:15.181042\n",
      "124 tensor(38064.5039, grad_fn=<AddBackward0>) 2019-11-13 19:01:54.021551\n",
      "125 tensor(37139.8438, grad_fn=<AddBackward0>) 2019-11-13 19:02:31.499839\n",
      "126 tensor(36263.5391, grad_fn=<AddBackward0>) 2019-11-13 19:03:06.787674\n",
      "127 tensor(35407.6367, grad_fn=<AddBackward0>) 2019-11-13 19:03:44.845058\n",
      "128 tensor(34591.0742, grad_fn=<AddBackward0>) 2019-11-13 19:04:24.669146\n",
      "129 tensor(33800.2109, grad_fn=<AddBackward0>) 2019-11-13 19:05:01.179282\n",
      "130 tensor(33046.1445, grad_fn=<AddBackward0>) 2019-11-13 19:05:39.169699\n",
      "131 tensor(32313.2910, grad_fn=<AddBackward0>) 2019-11-13 19:06:13.688115\n",
      "132 tensor(31615.3184, grad_fn=<AddBackward0>) 2019-11-13 19:06:47.342919\n",
      "133 tensor(30936.8535, grad_fn=<AddBackward0>) 2019-11-13 19:07:23.174421\n",
      "134 tensor(30292.1484, grad_fn=<AddBackward0>) 2019-11-13 19:08:00.905491\n",
      "135 tensor(29665.5957, grad_fn=<AddBackward0>) 2019-11-13 19:08:37.213752\n",
      "136 tensor(29071.3398, grad_fn=<AddBackward0>) 2019-11-13 19:09:14.776760\n",
      "137 tensor(28492.2461, grad_fn=<AddBackward0>) 2019-11-13 19:09:54.261278\n",
      "138 tensor(27943.6738, grad_fn=<AddBackward0>) 2019-11-13 19:10:31.483614\n",
      "139 tensor(27409.7539, grad_fn=<AddBackward0>) 2019-11-13 19:11:07.603989\n",
      "140 tensor(26904.0508, grad_fn=<AddBackward0>) 2019-11-13 19:11:45.655520\n",
      "141 tensor(26410.6426, grad_fn=<AddBackward0>) 2019-11-13 19:12:23.359584\n",
      "142 tensor(25945.9512, grad_fn=<AddBackward0>) 2019-11-13 19:12:58.802780\n",
      "143 tensor(25491.2852, grad_fn=<AddBackward0>) 2019-11-13 19:13:33.903713\n",
      "144 tensor(25063.5547, grad_fn=<AddBackward0>) 2019-11-13 19:14:10.627488\n",
      "145 tensor(24643.1523, grad_fn=<AddBackward0>) 2019-11-13 19:14:48.527867\n",
      "146 tensor(24250.4453, grad_fn=<AddBackward0>) 2019-11-13 19:15:21.131936\n",
      "147 tensor(23862.1328, grad_fn=<AddBackward0>) 2019-11-13 19:15:59.586860\n",
      "148 tensor(23499.1406, grad_fn=<AddBackward0>) 2019-11-13 19:16:37.249495\n",
      "149 tensor(23142.9414, grad_fn=<AddBackward0>) 2019-11-13 19:17:14.618636\n",
      "150 tensor(22809.7910, grad_fn=<AddBackward0>) 2019-11-13 19:17:52.297970\n",
      "151 tensor(22481.6582, grad_fn=<AddBackward0>) 2019-11-13 19:18:31.232138\n",
      "152 tensor(22175.3125, grad_fn=<AddBackward0>) 2019-11-13 19:19:06.360518\n",
      "153 tensor(21872.2402, grad_fn=<AddBackward0>) 2019-11-13 19:19:43.497229\n",
      "154 tensor(21591.4316, grad_fn=<AddBackward0>) 2019-11-13 19:20:16.195933\n",
      "155 tensor(21312.4219, grad_fn=<AddBackward0>) 2019-11-13 19:20:52.400454\n",
      "156 tensor(21055.8867, grad_fn=<AddBackward0>) 2019-11-13 19:21:24.765773\n",
      "157 tensor(20797.3574, grad_fn=<AddBackward0>) 2019-11-13 19:22:01.219888\n",
      "158 tensor(20561.0430, grad_fn=<AddBackward0>) 2019-11-13 19:22:34.059596\n",
      "159 tensor(20325.7988, grad_fn=<AddBackward0>) 2019-11-13 19:23:05.981201\n",
      "160 tensor(20106.4922, grad_fn=<AddBackward0>) 2019-11-13 19:23:39.611432\n",
      "161 tensor(19887.9980, grad_fn=<AddBackward0>) 2019-11-13 19:24:15.636945\n",
      "162 tensor(19685.8379, grad_fn=<AddBackward0>) 2019-11-13 19:24:50.974111\n",
      "163 tensor(19485.1973, grad_fn=<AddBackward0>) 2019-11-13 19:25:27.319074\n",
      "164 tensor(19300.3379, grad_fn=<AddBackward0>) 2019-11-13 19:26:03.312270\n",
      "165 tensor(19113.7773, grad_fn=<AddBackward0>) 2019-11-13 19:26:42.828890\n",
      "166 tensor(18941.4355, grad_fn=<AddBackward0>) 2019-11-13 19:27:18.647588\n",
      "167 tensor(18769.5137, grad_fn=<AddBackward0>) 2019-11-13 19:27:57.359772\n",
      "168 tensor(18612.2949, grad_fn=<AddBackward0>) 2019-11-13 19:28:33.675004\n",
      "169 tensor(18452.7949, grad_fn=<AddBackward0>) 2019-11-13 19:29:10.226333\n",
      "170 tensor(18306.6719, grad_fn=<AddBackward0>) 2019-11-13 19:29:44.603900\n",
      "171 tensor(18159.0488, grad_fn=<AddBackward0>) 2019-11-13 19:30:20.120191\n",
      "172 tensor(18024.3730, grad_fn=<AddBackward0>) 2019-11-13 19:30:57.553552\n",
      "173 tensor(17888.0293, grad_fn=<AddBackward0>) 2019-11-13 19:31:33.864475\n",
      "174 tensor(17763.5547, grad_fn=<AddBackward0>) 2019-11-13 19:32:12.342801\n",
      "175 tensor(17638.4141, grad_fn=<AddBackward0>) 2019-11-13 19:32:49.348523\n",
      "176 tensor(17521.7324, grad_fn=<AddBackward0>) 2019-11-13 19:33:28.190835\n",
      "177 tensor(17406.6348, grad_fn=<AddBackward0>) 2019-11-13 19:34:03.550723\n",
      "178 tensor(17299.5723, grad_fn=<AddBackward0>) 2019-11-13 19:34:37.954419\n",
      "179 tensor(17191.8945, grad_fn=<AddBackward0>) 2019-11-13 19:35:17.768531\n",
      "180 tensor(17092.1758, grad_fn=<AddBackward0>) 2019-11-13 19:35:54.536795\n",
      "181 tensor(16992.7793, grad_fn=<AddBackward0>) 2019-11-13 19:36:31.377311\n",
      "182 tensor(16900.6855, grad_fn=<AddBackward0>) 2019-11-13 19:37:06.546294\n",
      "183 tensor(16807.4355, grad_fn=<AddBackward0>) 2019-11-13 19:37:45.145022\n",
      "184 tensor(16722.5625, grad_fn=<AddBackward0>) 2019-11-13 19:38:18.715890\n",
      "185 tensor(16635.8965, grad_fn=<AddBackward0>) 2019-11-13 19:38:55.681330\n",
      "186 tensor(16557.9375, grad_fn=<AddBackward0>) 2019-11-13 19:39:34.254677\n",
      "187 tensor(16476.1953, grad_fn=<AddBackward0>) 2019-11-13 19:40:11.021684\n",
      "188 tensor(16404.5352, grad_fn=<AddBackward0>) 2019-11-13 19:40:44.997461\n",
      "189 tensor(16327.9229, grad_fn=<AddBackward0>) 2019-11-13 19:41:21.481435\n",
      "190 tensor(16260.5264, grad_fn=<AddBackward0>) 2019-11-13 19:41:56.691549\n",
      "191 tensor(16188.7832, grad_fn=<AddBackward0>) 2019-11-13 19:42:34.047983\n",
      "192 tensor(16126.3115, grad_fn=<AddBackward0>) 2019-11-13 19:43:09.747845\n",
      "193 tensor(16059.5264, grad_fn=<AddBackward0>) 2019-11-13 19:43:43.999649\n",
      "194 tensor(16001.4863, grad_fn=<AddBackward0>) 2019-11-13 19:44:23.098976\n",
      "195 tensor(15937.9268, grad_fn=<AddBackward0>) 2019-11-13 19:45:00.473638\n",
      "196 tensor(15884.0312, grad_fn=<AddBackward0>) 2019-11-13 19:45:37.216286\n",
      "197 tensor(15824.1533, grad_fn=<AddBackward0>) 2019-11-13 19:46:14.279887\n",
      "198 tensor(15773.9902, grad_fn=<AddBackward0>) 2019-11-13 19:46:48.103435\n",
      "199 tensor(15718.0225, grad_fn=<AddBackward0>) 2019-11-13 19:47:23.627980\n",
      "200 tensor([ 1.0000, -1.0000, -0.9593,  ...,  1.0000, -1.0000,  1.0000])\n"
     ]
    }
   ],
   "source": [
    "alpha = 1e-4; step = 1; eps = 0.1\n",
    "optimizer = torch.optim.RMSprop([W])\n",
    "loss_lst = []\n",
    "while True:\n",
    "    loss = loss_func(X, Y, W)\n",
    "    print(step, loss, datetime.datetime.now())\n",
    "    loss_lst.append(loss.item())\n",
    "    W.retain_grad() \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    #with torch.no_grad():\n",
    "    #    W = (W - alpha * W.grad)\n",
    "    #W.requires_grad_(True)\n",
    "    step += 1\n",
    "    if step % 100 == 0:\n",
    "        print(step, Y)\n",
    "    if step >= 200:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 tensor(15671.2461, grad_fn=<AddBackward0>) 2019-11-13 19:53:51.326466\n",
      "201 tensor(15618.3936, grad_fn=<AddBackward0>) 2019-11-13 19:54:23.337817\n",
      "202 tensor(15574.8125, grad_fn=<AddBackward0>) 2019-11-13 19:54:55.883014\n",
      "203 tensor(15525.1709, grad_fn=<AddBackward0>) 2019-11-13 19:55:24.314034\n",
      "204 tensor(15483.9473, grad_fn=<AddBackward0>) 2019-11-13 19:55:53.981627\n",
      "205 tensor(15437.6680, grad_fn=<AddBackward0>) 2019-11-13 19:56:25.227527\n",
      "206 tensor(15399.0078, grad_fn=<AddBackward0>) 2019-11-13 19:56:55.289340\n",
      "207 tensor(15355.0898, grad_fn=<AddBackward0>) 2019-11-13 19:57:23.663350\n",
      "208 tensor(15318.3193, grad_fn=<AddBackward0>) 2019-11-13 19:57:53.983919\n",
      "209 tensor(15277.4219, grad_fn=<AddBackward0>) 2019-11-13 19:58:26.028543\n",
      "210 tensor(15242.8662, grad_fn=<AddBackward0>) 2019-11-13 19:58:54.294908\n",
      "211 tensor(15204.8408, grad_fn=<AddBackward0>) 2019-11-13 19:59:25.879080\n",
      "212 tensor(15171.7725, grad_fn=<AddBackward0>) 2019-11-13 19:59:58.978591\n",
      "213 tensor(15135.8721, grad_fn=<AddBackward0>) 2019-11-13 20:00:29.328984\n",
      "214 tensor(15104.6533, grad_fn=<AddBackward0>) 2019-11-13 20:01:01.320444\n",
      "215 tensor(15070.8896, grad_fn=<AddBackward0>) 2019-11-13 20:01:30.597567\n",
      "216 tensor(15041.5117, grad_fn=<AddBackward0>) 2019-11-13 20:02:00.627732\n",
      "217 tensor(15009.0059, grad_fn=<AddBackward0>) 2019-11-13 20:02:29.723522\n",
      "218 tensor(14981.7334, grad_fn=<AddBackward0>) 2019-11-13 20:02:58.303098\n",
      "219 tensor(14950.8672, grad_fn=<AddBackward0>) 2019-11-13 20:03:30.777235\n",
      "220 tensor(14925.1211, grad_fn=<AddBackward0>) 2019-11-13 20:04:00.333786\n",
      "221 tensor(14895.8018, grad_fn=<AddBackward0>) 2019-11-13 20:04:30.269330\n",
      "222 tensor(14871.1982, grad_fn=<AddBackward0>) 2019-11-13 20:05:00.029594\n",
      "223 tensor(14843.5898, grad_fn=<AddBackward0>) 2019-11-13 20:05:30.663050\n",
      "224 tensor(14820.1729, grad_fn=<AddBackward0>) 2019-11-13 20:06:03.714279\n",
      "225 tensor(14794.1465, grad_fn=<AddBackward0>) 2019-11-13 20:06:35.843718\n",
      "226 tensor(14771.8486, grad_fn=<AddBackward0>) 2019-11-13 20:07:09.040882\n",
      "227 tensor(14746.5996, grad_fn=<AddBackward0>) 2019-11-13 20:07:39.528486\n",
      "228 tensor(14725.4980, grad_fn=<AddBackward0>) 2019-11-13 20:08:10.305620\n",
      "229 tensor(14701.8975, grad_fn=<AddBackward0>) 2019-11-13 20:08:38.378591\n",
      "230 tensor(14681.6113, grad_fn=<AddBackward0>) 2019-11-13 20:09:08.970667\n",
      "231 tensor(14659.2480, grad_fn=<AddBackward0>) 2019-11-13 20:09:38.920656\n",
      "232 tensor(14640.2959, grad_fn=<AddBackward0>) 2019-11-13 20:10:06.824964\n",
      "233 tensor(14618.5830, grad_fn=<AddBackward0>) 2019-11-13 20:10:39.993148\n",
      "234 tensor(14600.5166, grad_fn=<AddBackward0>) 2019-11-13 20:11:11.226714\n",
      "235 tensor(14579.9502, grad_fn=<AddBackward0>) 2019-11-13 20:11:41.422289\n",
      "236 tensor(14562.1650, grad_fn=<AddBackward0>) 2019-11-13 20:12:12.322256\n",
      "237 tensor(14543.0068, grad_fn=<AddBackward0>) 2019-11-13 20:12:44.670008\n",
      "238 tensor(14526.2227, grad_fn=<AddBackward0>) 2019-11-13 20:13:15.185544\n",
      "239 tensor(14507.6553, grad_fn=<AddBackward0>) 2019-11-13 20:13:45.971180\n",
      "240 tensor(14491.1309, grad_fn=<AddBackward0>) 2019-11-13 20:14:17.487675\n",
      "241 tensor(14473.9990, grad_fn=<AddBackward0>) 2019-11-13 20:14:47.830909\n",
      "242 tensor(14457.7246, grad_fn=<AddBackward0>) 2019-11-13 20:15:17.382743\n",
      "243 tensor(14441.2881, grad_fn=<AddBackward0>) 2019-11-13 20:15:47.742451\n",
      "244 tensor(14425.7783, grad_fn=<AddBackward0>) 2019-11-13 20:16:13.993464\n",
      "245 tensor(14410.0439, grad_fn=<AddBackward0>) 2019-11-13 20:16:43.183735\n",
      "246 tensor(14395.0205, grad_fn=<AddBackward0>) 2019-11-13 20:17:12.714364\n",
      "247 tensor(14379.9502, grad_fn=<AddBackward0>) 2019-11-13 20:17:49.451293\n",
      "248 tensor(14365.6133, grad_fn=<AddBackward0>) 2019-11-13 20:18:24.355263\n",
      "249 tensor(14350.9404, grad_fn=<AddBackward0>) 2019-11-13 20:18:56.889471\n",
      "250 tensor(14337.1055, grad_fn=<AddBackward0>) 2019-11-13 20:19:28.017069\n",
      "251 tensor(14322.8232, grad_fn=<AddBackward0>) 2019-11-13 20:20:02.835459\n",
      "252 tensor(14309.4932, grad_fn=<AddBackward0>) 2019-11-13 20:20:36.236923\n",
      "253 tensor(14295.8691, grad_fn=<AddBackward0>) 2019-11-13 20:21:09.962626\n",
      "254 tensor(14283.4443, grad_fn=<AddBackward0>) 2019-11-13 20:21:42.329656\n",
      "255 tensor(14269.8574, grad_fn=<AddBackward0>) 2019-11-13 20:22:14.630657\n",
      "256 tensor(14257.5039, grad_fn=<AddBackward0>) 2019-11-13 20:22:46.907413\n",
      "257 tensor(14244.3838, grad_fn=<AddBackward0>) 2019-11-13 20:23:19.563869\n",
      "258 tensor(14233.0664, grad_fn=<AddBackward0>) 2019-11-13 20:23:53.920012\n",
      "259 tensor(14220.2061, grad_fn=<AddBackward0>) 2019-11-13 20:24:24.111669\n",
      "260 tensor(14209.2090, grad_fn=<AddBackward0>) 2019-11-13 20:24:58.628113\n",
      "261 tensor(14196.7783, grad_fn=<AddBackward0>) 2019-11-13 20:25:32.931686\n",
      "262 tensor(14185.9834, grad_fn=<AddBackward0>) 2019-11-13 20:26:07.400426\n",
      "263 tensor(14173.9268, grad_fn=<AddBackward0>) 2019-11-13 20:26:41.867710\n",
      "264 tensor(14163.6826, grad_fn=<AddBackward0>) 2019-11-13 20:27:13.169501\n",
      "265 tensor(14152.1523, grad_fn=<AddBackward0>) 2019-11-13 20:27:49.497170\n",
      "266 tensor(14141.7959, grad_fn=<AddBackward0>) 2019-11-13 20:28:21.668682\n",
      "267 tensor(14130.9082, grad_fn=<AddBackward0>) 2019-11-13 20:28:53.546658\n",
      "268 tensor(14120.8721, grad_fn=<AddBackward0>) 2019-11-13 20:29:27.811395\n",
      "269 tensor(14110.2529, grad_fn=<AddBackward0>) 2019-11-13 20:30:00.672051\n",
      "270 tensor(14100.4395, grad_fn=<AddBackward0>) 2019-11-13 20:30:34.903391\n",
      "271 tensor(14090.4131, grad_fn=<AddBackward0>) 2019-11-13 20:31:09.311859\n",
      "272 tensor(14080.6182, grad_fn=<AddBackward0>) 2019-11-13 20:31:41.713447\n",
      "273 tensor(14071.0020, grad_fn=<AddBackward0>) 2019-11-13 20:32:10.514514\n",
      "274 tensor(14061.3574, grad_fn=<AddBackward0>) 2019-11-13 20:32:40.610605\n",
      "275 tensor(14052.2275, grad_fn=<AddBackward0>) 2019-11-13 20:33:06.579127\n",
      "276 tensor(14042.8105, grad_fn=<AddBackward0>) 2019-11-13 20:33:35.587473\n",
      "277 tensor(14034.0781, grad_fn=<AddBackward0>) 2019-11-13 20:34:06.250593\n",
      "278 tensor(14024.8125, grad_fn=<AddBackward0>) 2019-11-13 20:34:33.075275\n",
      "279 tensor(14016.1357, grad_fn=<AddBackward0>) 2019-11-13 20:35:02.838911\n",
      "280 tensor(14007.2900, grad_fn=<AddBackward0>) 2019-11-13 20:35:32.417747\n",
      "281 tensor(13998.8975, grad_fn=<AddBackward0>) 2019-11-13 20:36:05.626045\n",
      "282 tensor(13990.4346, grad_fn=<AddBackward0>) 2019-11-13 20:36:36.054885\n",
      "283 tensor(13982.1240, grad_fn=<AddBackward0>) 2019-11-13 20:37:06.736021\n",
      "284 tensor(13973.8242, grad_fn=<AddBackward0>) 2019-11-13 20:37:37.756238\n",
      "285 tensor(13965.8252, grad_fn=<AddBackward0>) 2019-11-13 20:38:10.547995\n",
      "286 tensor(13957.8145, grad_fn=<AddBackward0>) 2019-11-13 20:38:41.097783\n",
      "287 tensor(13950.0547, grad_fn=<AddBackward0>) 2019-11-13 20:39:11.738468\n",
      "288 tensor(13942.1016, grad_fn=<AddBackward0>) 2019-11-13 20:39:43.036549\n",
      "289 tensor(13934.8184, grad_fn=<AddBackward0>) 2019-11-13 20:40:18.725978\n",
      "290 tensor(13927., grad_fn=<AddBackward0>) 2019-11-13 20:40:51.912000\n",
      "291 tensor(13919.9209, grad_fn=<AddBackward0>) 2019-11-13 20:41:24.559573\n",
      "292 tensor(13912.0596, grad_fn=<AddBackward0>) 2019-11-13 20:41:53.211504\n",
      "293 tensor(13905.3838, grad_fn=<AddBackward0>) 2019-11-13 20:42:25.681985\n",
      "294 tensor(13897.6260, grad_fn=<AddBackward0>) 2019-11-13 20:42:55.467626\n",
      "295 tensor(13891.2891, grad_fn=<AddBackward0>) 2019-11-13 20:43:27.218512\n",
      "296 tensor(13883.6367, grad_fn=<AddBackward0>) 2019-11-13 20:43:58.204667\n",
      "297 tensor(13877.5801, grad_fn=<AddBackward0>) 2019-11-13 20:44:31.309765\n",
      "298 tensor(13869.9990, grad_fn=<AddBackward0>) 2019-11-13 20:45:04.447726\n",
      "299 tensor(13864.2900, grad_fn=<AddBackward0>) 2019-11-13 20:45:36.075732\n",
      "300 tensor([ 1.0000, -1.0000, -0.9593,  ...,  1.0000, -1.0000,  1.0000])\n",
      "300 tensor(13856.8457, grad_fn=<AddBackward0>) 2019-11-13 20:46:05.069352\n",
      "301 tensor(13851.2412, grad_fn=<AddBackward0>) 2019-11-13 20:46:37.238529\n",
      "302 tensor(13843.8428, grad_fn=<AddBackward0>) 2019-11-13 20:47:09.810170\n",
      "303 tensor(13838.4863, grad_fn=<AddBackward0>) 2019-11-13 20:47:43.757811\n",
      "304 tensor(13831.4150, grad_fn=<AddBackward0>) 2019-11-13 20:48:13.956581\n",
      "305 tensor(13826.1963, grad_fn=<AddBackward0>) 2019-11-13 20:48:41.096738\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-c4896889f44f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/yz3453/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/yz3453/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    loss = loss_func(X, Y, W)\n",
    "    print(step, loss, datetime.datetime.now())\n",
    "    loss_lst.append(loss.item())\n",
    "    W.retain_grad() \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    #with torch.no_grad():\n",
    "    #    W = (W - alpha * W.grad)\n",
    "    #W.requires_grad_(True)\n",
    "    step += 1\n",
    "    if step % 100 == 0:\n",
    "        print(step, Y)\n",
    "    if step >= 500:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_sav = W.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 29325)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_sav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./data/factor_mat.csv', W_sav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/news_guardian_cuttedentity.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc027364278>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
